{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c07113b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124800, 784) (124800,)\n"
     ]
    }
   ],
   "source": [
    "### 1. import data\n",
    " \n",
    "from mnist import MNIST\n",
    " \n",
    "data = MNIST(path='data/', return_type='numpy')\n",
    "data.select_emnist('letters')\n",
    "X, y = data.load_training()\n",
    " \n",
    "print(X.shape, y.shape) # 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "924aac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(124800, 28, 28)\n",
    "y = y.reshape(124800, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad7bfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(y) #--> y ranges from 1 to 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71300bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b18b549",
   "metadata": {},
   "outputs": [],
   "source": [
    " #list(y) #--> y ranges from 1 to 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "230c2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. train-test split\n",
    " \n",
    "# pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd63841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8feca051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0,255) --> (0,1)\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9831e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32c9462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# integer into one hot vector (binary class matrix)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=26)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c59b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0799445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. Define our model\n",
    " \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Preventing overfitting\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(26, activation='softmax'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c632e24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 26)                13338     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 677914 (2.59 MB)\n",
      "Trainable params: 677914 (2.59 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f64399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66a5a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, test accuracy is 4.767628386616707\n"
     ]
    }
   ],
   "source": [
    "### 4. calculate accuracy\n",
    " \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100 * score[1]\n",
    "print(\"Before training, test accuracy is\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4dfad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "623/624 [============================>.] - ETA: 0s - loss: 0.1859 - accuracy: 0.9330\n",
      "Epoch 1: val_loss improved from inf to 0.28391, saving model to best_model\n",
      "INFO:tensorflow:Assets written to: best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 23s 35ms/step - loss: 0.1859 - accuracy: 0.9330 - val_loss: 0.2839 - val_accuracy: 0.9163\n",
      "Epoch 2/10\n",
      "623/624 [============================>.] - ETA: 0s - loss: 0.1730 - accuracy: 0.9365\n",
      "Epoch 2: val_loss did not improve from 0.28391\n",
      "624/624 [==============================] - 20s 32ms/step - loss: 0.1729 - accuracy: 0.9366 - val_loss: 0.2864 - val_accuracy: 0.9135\n",
      "Epoch 3/10\n",
      "624/624 [==============================] - ETA: 0s - loss: 0.1637 - accuracy: 0.9386\n",
      "Epoch 3: val_loss did not improve from 0.28391\n",
      "624/624 [==============================] - 20s 31ms/step - loss: 0.1637 - accuracy: 0.9386 - val_loss: 0.3011 - val_accuracy: 0.9132\n",
      "Epoch 4/10\n",
      "623/624 [============================>.] - ETA: 0s - loss: 0.1550 - accuracy: 0.9422\n",
      "Epoch 4: val_loss did not improve from 0.28391\n",
      "624/624 [==============================] - 19s 30ms/step - loss: 0.1552 - accuracy: 0.9421 - val_loss: 0.2977 - val_accuracy: 0.9158\n",
      "Epoch 5/10\n",
      "624/624 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.9429\n",
      "Epoch 5: val_loss did not improve from 0.28391\n",
      "624/624 [==============================] - 19s 31ms/step - loss: 0.1513 - accuracy: 0.9429 - val_loss: 0.2988 - val_accuracy: 0.9157\n",
      "Epoch 6/10\n",
      "622/624 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9444\n",
      "Epoch 6: val_loss did not improve from 0.28391\n",
      "624/624 [==============================] - 19s 31ms/step - loss: 0.1463 - accuracy: 0.9443 - val_loss: 0.3124 - val_accuracy: 0.9155\n",
      "Epoch 7/10\n",
      "623/624 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9463\n",
      "Epoch 7: val_loss did not improve from 0.28391\n",
      "624/624 [==============================] - 19s 31ms/step - loss: 0.1408 - accuracy: 0.9463 - val_loss: 0.2964 - val_accuracy: 0.9185\n",
      "Epoch 8/10\n",
      "623/624 [============================>.] - ETA: 0s - loss: 0.1366 - accuracy: 0.9480\n",
      "Epoch 8: val_loss did not improve from 0.28391\n",
      "624/624 [==============================] - 19s 31ms/step - loss: 0.1365 - accuracy: 0.9480 - val_loss: 0.2965 - val_accuracy: 0.9176\n",
      "Epoch 9/10\n",
      "624/624 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9490\n",
      "Epoch 9: val_loss did not improve from 0.28391\n",
      "624/624 [==============================] - 19s 31ms/step - loss: 0.1329 - accuracy: 0.9490 - val_loss: 0.3041 - val_accuracy: 0.9182\n",
      "Epoch 10/10\n",
      "624/624 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.9503\n",
      "Epoch 10: val_loss did not improve from 0.28391\n",
      "624/624 [==============================] - 19s 30ms/step - loss: 0.1276 - accuracy: 0.9503 - val_loss: 0.3157 - val_accuracy: 0.9162\n",
      "After training, test accuracy is 91.35817289352417\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='best_model', verbose=1, save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=10, \n",
    "                    validation_split=0.2, callbacks=[checkpointer], verbose=1, shuffle=True)\n",
    "\n",
    "# After training, load the best model\n",
    "model = tf.keras.models.load_model('best_model')\n",
    "\n",
    "# Calculate accuracy after training\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100 * score[1]\n",
    "print(\"After training, test accuracy is\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0653e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    " \n",
    "model = tf.keras.models.load_model('best_model')\n",
    " \n",
    "letters ={ 0:'a', 1:'b', 2:'c', 3:'d', 4:'e', 5:'f', 6:'g', 7:'h', 8:'i', 9:'j', 10:'k', 11:'l', \n",
    "          12:'m', 13:'n', 14:'o', 15:'p', 16:'q', 17:'r', 18:'s', 19:'t', 20:'u', 21:'v', 22:'w', \n",
    "          23:'x', 24:'y', 25:'z', 26:''}\n",
    " \n",
    "# defining blue color in hsv format\n",
    "# pip install numpy\n",
    "import numpy as np\n",
    " \n",
    "blueLower = np.array([100,60,60])\n",
    "blueUpper = np.array([140,255,255])\n",
    " \n",
    "kernel = np.ones((5,5), np.uint8)\n",
    " \n",
    "# define blackboard\n",
    "blackboard = np.zeros((480,640, 3), dtype=np.uint8)\n",
    "alphabet = np.zeros((200,200,3), dtype=np.uint8)\n",
    " \n",
    "# deques (Double ended queue) is used to store alphabet drawn on screen\n",
    "from collections import deque\n",
    "points = deque(maxlen = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc4e285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2 #pip install opencv-python\n",
    "cap = cv2.VideoCapture(0)\n",
    "prediction = 26\n",
    "while True:\n",
    "    ret, frame=cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "     \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    # Detecting which pixel value falls under blue color boundaries\n",
    "    blue = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "     \n",
    "    #erosion\n",
    "    blue = cv2.erode(blue, kernel)\n",
    "    #opening\n",
    "    blue = cv2.morphologyEx(blue, cv2.MORPH_OPEN, kernel)\n",
    "    #dilation\n",
    "    blue = cv2.dilate(blue, kernel)\n",
    "     \n",
    "    # find countours in the image\n",
    "    cnts , _ = cv2.findContours(blue, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "    center = None\n",
    "     \n",
    "    # if any countours were found\n",
    "    if len(cnts) > 0:\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse=True)[0]\n",
    "        ((x,y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        cv2.circle(frame, (int(x), int(y),), int(radius), (125,344,278), 2)\n",
    "         \n",
    "        M = cv2.moments(cnt)\n",
    "        center = (int(M['m10']/M['m00']), int(M['m01']/M['m00']))\n",
    "     \n",
    "        points.appendleft(center)\n",
    "         \n",
    "    elif len(cnts) == 0:\n",
    "        if len(points) != 0:\n",
    "            blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "            blur = cv2.medianBlur(blackboard_gray, 15)\n",
    "            blur = cv2.GaussianBlur(blur, (5,5), 0)\n",
    "            thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "            cv2.imshow(\"Thresh\", thresh)\n",
    "             \n",
    "            blackboard_cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[0]\n",
    "             \n",
    "            if len(blackboard_cnts)>=1:\n",
    "                cnt = sorted(blackboard_cnts, key=cv2.contourArea, reverse=True)[0]\n",
    "                 \n",
    "                if cv2.contourArea(cnt)>1000:\n",
    "                    x,y,w,h = cv2.boundingRect(cnt)\n",
    "                    alphabet = blackboard_gray[y-10:y+h+10,x-10:x+w+10]\n",
    "                    try:\n",
    "                        img = cv2.resize(alphabet, (28,28))\n",
    "                    except cv2.error as e:\n",
    "                        continue\n",
    "                     \n",
    "                    img = np.array(img)\n",
    "                    img = img.astype('float32')/255\n",
    "                     \n",
    "                    prediction = model.predict(img.reshape(1,28,28))[0]\n",
    "                    prediction = np.argmax(prediction)\n",
    "                     \n",
    "            # Empty the point deque and also blackboard\n",
    "            points = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480,640, 3), dtype=np.uint8)\n",
    "         \n",
    "    # connect the detected points with line\n",
    "    for i in range(1, len(points)):\n",
    "        if points[i-1] is None or points[i] is None:\n",
    "            continue\n",
    "        cv2.line(frame, points[i-1], points[i], (0,0,0), 2)\n",
    "        cv2.line(blackboard, points[i-1], points[i], (255,255,255), 8)\n",
    "         \n",
    "     \n",
    "    cv2.putText(frame, \"Prediction: \" + str(letters[int(prediction)]), (20,400), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "     \n",
    "     \n",
    "    cv2.imshow(\"Alphabet Recognition System\", frame)\n",
    "     \n",
    "    if cv2.waitKey(1)==13: #if I press enter\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8e3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1bc32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af70d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Recognized Alphabets: GAKBCBBDCCEFGHIJKKLMNOPRQKRBBKSPTWUVWXYDWXZ\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define color boundaries for blue\n",
    "blueLower = np.array([100, 60, 60])\n",
    "blueUpper = np.array([140, 255, 255])\n",
    "\n",
    "# Create kernel for morphological transformations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Initialize deque to store points\n",
    "points = deque(maxlen=512)\n",
    "\n",
    "# Initialize blackboard to draw on\n",
    "blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# Load your model\n",
    "model = tf.keras.models.load_model('best_model')  # Replace 'your_model_path.h5' with your model path\n",
    "\n",
    "# Define letters (adjust this as per your model's output)\n",
    "letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "# Initialize a list to store recognized alphabets\n",
    "recognized_alphabets = []\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "prediction = 26\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    # Detecting which pixel value falls under blue color boundaries\n",
    "    blue = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "     \n",
    "    # Erosion, opening, and dilation\n",
    "    blue = cv2.erode(blue, kernel)\n",
    "    blue = cv2.morphologyEx(blue, cv2.MORPH_OPEN, kernel)\n",
    "    blue = cv2.dilate(blue, kernel)\n",
    "     \n",
    "    # Find contours in the image\n",
    "    cnts, _ = cv2.findContours(blue, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "    center = None\n",
    "     \n",
    "    # If any contours were found\n",
    "    if len(cnts) > 0:\n",
    "        cnt = sorted(cnts, key=cv2.contourArea, reverse=True)[0]\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        cv2.circle(frame, (int(x), int(y)), int(radius), (125, 344, 278), 2)\n",
    "         \n",
    "        M = cv2.moments(cnt)\n",
    "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "     \n",
    "        points.appendleft(center)\n",
    "         \n",
    "    elif len(cnts) == 0:\n",
    "        if len(points) != 0:\n",
    "            blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "            blur = cv2.medianBlur(blackboard_gray, 15)\n",
    "            blur = cv2.GaussianBlur(blur, (5, 5), 0)\n",
    "            thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "            cv2.imshow(\"Thresh\", thresh)\n",
    "             \n",
    "            blackboard_cnts, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "             \n",
    "            if len(blackboard_cnts) >= 1:\n",
    "                cnt = sorted(blackboard_cnts, key=cv2.contourArea, reverse=True)[0]\n",
    "                 \n",
    "                if cv2.contourArea(cnt) > 1000:\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    alphabet = blackboard_gray[y-10:y+h+10, x-10:x+w+10]\n",
    "                    try:\n",
    "                        img = cv2.resize(alphabet, (28, 28))\n",
    "                    except cv2.error as e:\n",
    "                        continue\n",
    "                     \n",
    "                    img = np.array(img)\n",
    "                    img = img.astype('float32') / 255\n",
    "                     \n",
    "                    prediction = model.predict(img.reshape(1, 28, 28))[0]\n",
    "                    prediction = np.argmax(prediction)\n",
    "                    \n",
    "                    # Append the recognized alphabet to the list\n",
    "                    recognized_alphabets.append(letters[prediction])\n",
    "                     \n",
    "            # Empty the point deque and also blackboard\n",
    "            points = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "         \n",
    "    # Connect the detected points with a line\n",
    "    for i in range(1, len(points)):\n",
    "        if points[i-1] is None or points[i] is None:\n",
    "            continue\n",
    "        cv2.line(frame, points[i-1], points[i], (0, 0, 0), 2)\n",
    "        cv2.line(blackboard, points[i-1], points[i], (255, 255, 255), 8)\n",
    "         \n",
    "    # Ensure the prediction is within the valid range\n",
    "    if 0 <= prediction < len(letters):\n",
    "        cv2.putText(frame, \"Prediction: \" + str(letters[prediction]), (20, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "     \n",
    "    cv2.imshow(\"Alphabet Recognition System\", frame)\n",
    "     \n",
    "    if cv2.waitKey(1) == 13:  # if I press enter\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Join the recognized alphabets into a single string and print it\n",
    "recognized_string = ''.join(recognized_alphabets)\n",
    "print(\"Recognized Alphabets:\", recognized_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39918ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5ac58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e608718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f814d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780d9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774797f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc104a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ec8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c3f969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
